[TOC]

### 哈希算法

* 将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制串就是哈希值
* 设计一个优秀哈希算法的要求
  * 从哈希值不能反向推导出原始数据（单向哈希算法）；
  * 对输入数据非常敏感，哪怕原始数据指修改了一个Bit，最后得到的哈希值也大不相同；
  * 散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；
  * 哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

##### 哈希算法的应用

###### 安全加密

* 常用于加密的哈希算法有MD5*消息摘要算法*和SHA*安全散列算法*

* 还有DES*数据加密标准*和AES*高级加密标准*

* 重要要求

  * 很难通过哈希值反向推导原始数据
  * 尽量减少碰撞冲突的概率

  > 理论上是没办法做到完全不冲突的——鸽巢原理

* 没有完全安全的加密，越复杂、越难破解的加密算法，需要计算时间也越长

* 选择哈希算法的时候，要权衡安全性和计算时间来决定用哪种哈希算法

###### 唯一标识

* 例如在海量图库中，搜索一张图片是否存在，不能单纯地用图片的元信息（图片名称）来对比，因为可能存在名称相同但图片内容不同，或者名称不同图片内容相同的情况

  > 任何文件在计算中都可以表示成二进制码串

* 给图片一个唯一标识——从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5 ），得到一个哈希字符串，用它作为图片的唯一标识。通过这个唯一标识来判定图片是否在图库中。

* 如果还想继续提高效率，我们可以把每个图片的**唯一标识**，和相应的图片文件在图库中的**路径信**
  **息**，都存储在散列表中。当要查看某个图片是不是在图库中的时候，我们先通过哈希算法对这个图片取唯一标识，然后在散列表中查找是否存在这个唯一标识。

  * 如果不存在，那就说明这个图片不在图库中；
  * 如果存在，我们再通过散列表中存储的文件路径，获取到这个已经存在的图片，跟现在要插入的图片做全量的比对，看是否完全一样。

  * 如果一样，就说明已经存在；
  * 如果不一样，说明两张图片尽管唯一标识相同，但是并不是相同的图片。

###### 数据校验

* BT下载的原理是基于P2P协议的。我们从多个机器上并行下载一个2GB的电影，这个电影文件可能会被分割成很多文件块（比如可以分成100块，每块大约20MB）。等所有文件都下载完成后，再组装成一个完整的电影文件。

  > 网络传输是不安全的，下载的文件块有可能是被宿主机器恶意修改过得，又或者下载过程中出现错误，所以下载的文件块不完整

* 数据校验

  * 通过哈希算法，对100个文件块分别取哈希值，并且保存在种子文件中。
  * 哈希算法对数据特别敏感，只要数据发生一点改变，最后计算出的哈希值就完全不同
  * 当文件下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值对比。
  * 如果不同，说明这个文件块不完整或者被篡改，需要重新从其他宿主机器上下载这个文件夹

###### 散列函数

* 散列函数中用到的散列算法，更加关注散列后的值能否平均分布，也就是，一组数据能否均匀地散列在各个槽中
* 散列函数用的哈希算法一般比较简单，比较追求效率

###### 负载均衡

> 会话粘滞（session sticky）也叫会话保持——确保来自相同客户端的请求，转发至后端相同的服务器进行处理。

如何才能实现一个会话粘滞的负载均衡算法？

* 维护一张映射表——客户端IP地址或者会话ID与服务器编号的映射关系；客户端每一次发送请求，都要先在映射表中查找应该路由到的服务器编号
  * 如果客户端很多，映射表可能会很大浪费内存空间
  * 客户端上线、下线，服务器扩容、缩容都会导致映射失效，这样维护映射表成本会很大
* 使用哈希算法——对客户端IP地址或者会话ID计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该路由到的服务器编号

###### 数据分片

1. 如何统计“搜索关键字“出现的次数？

* 假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？

  * 难点

    * 搜索日志很大，没办法放到一台机器的内存中
    * 如果使用一台机器处理这么巨大的数据，处理时间会很长

  * 解决——先对数据进行分片，采用多台机器处理的方式，来提高处理速度

    * 为了提高处理速度，使用用n台机器并行处理
    * 从搜索记录的日志文件中，依次读出每个搜索关键字，并且通过哈希函数计算哈希值，然后再跟n取模，最终得到的值，就是应该被分配到的机器编号
    * 哈希值相同的搜索关键词就被分配到了同一个机器上，也就是说，同一个关键词会被分配到同一台机器上，每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果

    > 这个处理过程也是MapReduce的基本设计思想

1. 如何快速判断图片是否在图库中？

   * 假设图库中有 1 亿张图片，而 1 亿张图片构建散列表显然远远超过了单台机器的内存上限
     * 对数据进行分片，然后采用多机处理
     * 我们准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。
     * 当我们要判断一个图片是否在图库中的时候，我们通过同样的哈希算法，计算这个图片的唯一标识，然后与机器个数 n 求余取模。假设得到的值是 k ，那就去编号 k 的机器构建的散列表中查找。

   > 针对海量数据的处理问题，我们都可以采用多机分布式处理。借助这种分片的思路，可以突破单机内存、CPU等资源的限制

###### 分布式存储

* 为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如分布式缓存。

* 如何决定将那个数据放到哪个机器上？

  * 我们可以借用前面数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号

  问题：数据增多，需要扩容

  * **一致性哈希算法**
    * 基本思想：假设我们有 k 个机器，数据的哈希值的范围是[0,MAX] 。我们将整个范围划分成 m 个小区间（ m 远大于 k ），每个机器负责 m/k 个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。
    * 除此之外，它还会借助一个虚拟的环和虚拟结点，更加优美地实现出来

---

##### 如何防止数据库中的用户信息被脱库？

* 我们可以通过哈希算法，对用户密码进行加密之后再存储，不过最好选择相对安全的加密算法，比
  如 SHA 等（因为 MD5 已经号称被破解了）
* 字典攻击——如果用户信息被 “ 脱库 ” ，黑客虽然拿到是加密之后的密文，但可以通过 “ 猜 ” 的
  方式来破解密码，这是因为，有些用户的密码太简单。比如很多人习惯用 00000 、 123456 这样的简单数字组合做密码，很容易就被猜中
* 针对字典攻击，我们可以引入一个盐（salt）,跟用户的密码组合在一起，增加密码的复杂度。我们拿组合之后的字符串来做哈希算法加密，将它存储到数据库中，进一步增加破解的难度。

##### 哈希算法在分布式系统中有哪些应用？

* 负载均衡、数据分片、分布式存储
* 在负载均衡应用中，利用哈希算法替代映射表，可以实现一个会话粘滞的负载均衡策略。
* 在数据分片应用中，通过哈希算法对处理的海量数据进行分片，多机分布式处理，可以突破单机资源的限制
* 在分布式存储应用中，利用一致性哈希算法，可以解决缓存分布式系统的扩容、缩容导致数据大量搬移的难题